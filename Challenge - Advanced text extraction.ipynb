{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'))\n",
    "\n",
    "df = pd.DataFrame([train_data.data, train_data.target.tolist()]).T\n",
    "\n",
    "df.columns = ['text', 'source']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_text = [x for x in train['text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the tf-idf matrix.\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "\n",
    "text_tfidf=vectorizer.fit_transform(df_text)\n",
    "\n",
    "terms = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of topics. I chose 6 because the 20 newgroups are separated into 6 categories\n",
    "ntopics=20\n",
    "\n",
    "# Linking words to topics\n",
    "def word_topic(tfidf,solution, wordlist):\n",
    "    \n",
    "    # Loading scores for each word on each topic/component.\n",
    "    words_by_topic=tfidf.T * solution\n",
    "\n",
    "    # Linking the loadings to the words in an easy-to-read way.\n",
    "    components=pd.DataFrame(words_by_topic,index=wordlist)\n",
    "    \n",
    "    return components\n",
    "\n",
    "# Extracts the top N words and their loadings for each topic.\n",
    "def top_words(components, n_top_words):\n",
    "    n_topics = range(components.shape[1])\n",
    "    index= np.repeat(n_topics, n_top_words, axis=0)\n",
    "    topwords=pd.Series(index=index)\n",
    "    for column in range(components.shape[1]):\n",
    "        # Sort the column so that highest loadings are at the top.\n",
    "        sortedwords=components.iloc[:,column].sort_values(ascending=False)\n",
    "        # Choose the N highest loadings.\n",
    "        chosen=sortedwords[:n_top_words]\n",
    "        # Combine loading and index into a string.\n",
    "        chosenlist=chosen.index +\" \"+round(chosen,2).map(str) \n",
    "        topwords.loc[column]=[x for x in chosenlist]\n",
    "    return(topwords)\n",
    "\n",
    "# Number of words to look at for each topic.\n",
    "n_top_words = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "svd= TruncatedSVD(ntopics)\n",
    "lsa = make_pipeline(svd, Normalizer(copy=False))\n",
    "\n",
    "tfidf_lsa = lsa.fit_transform(text_tfidf)\n",
    "\n",
    "components_lsa = word_topic(text_tfidf, tfidf_lsa, terms)\n",
    "\n",
    "topwords=pd.DataFrame()\n",
    "\n",
    "topwords['LSA']=top_words(components_lsa, n_top_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation as LDA\n",
    "\n",
    "lda = LDA(n_components=ntopics, \n",
    "          doc_topic_prior=None, # Prior = 1/n_documents\n",
    "          topic_word_prior=1/ntopics,\n",
    "          learning_decay=0.7, # Convergence rate.\n",
    "          learning_offset=10.0, # Causes earlier iterations to have less influence on the learning\n",
    "          max_iter=10, # when to stop even if the model is not converging (to prevent running forever)\n",
    "          evaluate_every=-1, # Do not evaluate perplexity, as it slows training time.\n",
    "          mean_change_tol=0.001, # Stop updating the document topic distribution in the E-step when mean change is < tol\n",
    "          max_doc_update_iter=100, # When to stop updating the document topic distribution in the E-step even if tol is not reached\n",
    "          n_jobs=-1, # Use all available CPUs to speed up processing time.\n",
    "          verbose=0, # amount of output to give while iterating\n",
    "          random_state=0\n",
    "         )\n",
    "\n",
    "tfidf_lda = lda.fit_transform(text_tfidf)\n",
    "\n",
    "components_lda = word_topic(text_tfidf, tfidf_lda, terms)\n",
    "\n",
    "topwords['LDA']=top_words(components_lda, n_top_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NNMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "\n",
    "nmf = NMF(alpha=0.0, \n",
    "          init='nndsvdar', # how starting value are calculated\n",
    "          l1_ratio=0.0, # Sets whether regularization is L2 (0), L1 (1), or a combination (values between 0 and 1)\n",
    "          max_iter=200, # when to stop even if the model is not converging (to prevent running forever)\n",
    "          n_components=ntopics, \n",
    "          random_state=0, \n",
    "          solver='cd', # Use Coordinate Descent to solve\n",
    "          tol=0.0001, # model will stop if tfidf-WH <= tol\n",
    "          verbose=0 # amount of output to give while iterating\n",
    "         )\n",
    "\n",
    "tfidf_nmf = nmf.fit_transform(text_tfidf)\n",
    "\n",
    "components_nmf = word_topic(text_tfidf, tfidf_nmf, terms)\n",
    "\n",
    "topwords['NNMF']=top_words(components_nmf, n_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\n",
      "            LSA          LDA         NNMF\n",
      "0    like 87.71    just 3.36    just 3.23\n",
      "0     don 86.87    know 3.21     don 3.22\n",
      "0    just 86.78    like 2.95   think 2.61\n",
      "0    know 80.91     don 2.89    like 2.49\n",
      "0  people 79.99    does 2.75  people 2.08\n",
      "0   think 75.08  people 2.71    know 1.99\n",
      "0    good 62.94   think 2.31    good 1.63\n",
      "0    does 62.42     use 2.11      ve 1.54\n",
      "0    time 61.86    good 2.11    time 1.51\n",
      "0     use 58.63     edu 2.05     say 1.43\n",
      "Topic 1:\n",
      "              LSA          LDA           NNMF\n",
      "1   windows 32.02    like 2.43        use 2.2\n",
      "1    thanks 30.77    just 2.36       mac 1.42\n",
      "1      card 20.64    does 2.31  software 1.26\n",
      "1     drive 19.07    know 2.27     apple 0.97\n",
      "1       dos 16.84     don 2.08      like 0.97\n",
      "1  software 16.51   think 2.03      need 0.88\n",
      "1       use 16.05  thanks 1.79   problem 0.87\n",
      "1        pc 15.68     use 1.73     modem 0.86\n",
      "1      file 15.48    time 1.64      used 0.84\n",
      "1      mail 15.46    good 1.61    memory 0.82\n",
      "Topic 2:\n",
      "                LSA          LDA             NNMF\n",
      "2         god 44.24    like 3.18         god 7.77\n",
      "2       jesus 19.09    know 2.76       jesus 3.35\n",
      "2     windows 14.27    just 2.66       bible 2.03\n",
      "2       bible 12.57     don 2.56     believe 1.85\n",
      "2      thanks 11.95    does 2.45      people 1.77\n",
      "2        does 11.63  thanks 2.41        faith 1.6\n",
      "2  christians 10.37   people 2.2      christ 1.55\n",
      "2   christian 10.08     edu 2.18   christian 1.52\n",
      "2        faith 9.56     use 2.09  christians 1.49\n",
      "2       christ 9.35    time 2.08         say 1.37\n",
      "Topic 3:\n",
      "               LSA          LDA             NNMF\n",
      "3        edu 17.42    like 2.91         geb 3.07\n",
      "3       pitt 11.64    know 2.85         dsl 3.04\n",
      "3  surrender 11.17    just 2.63       n3jxp 3.04\n",
      "3     gordon 11.16     don 2.48    chastity 3.04\n",
      "3        geb 10.96    does 2.38       cadre 3.04\n",
      "3      banks 10.87  thanks 2.22        pitt 3.03\n",
      "3       soon 10.82   think 2.08    shameful 3.03\n",
      "3   shameful 10.73     edu 2.04   intellect 3.01\n",
      "3       cadre 10.6  people 1.95  skepticism 3.01\n",
      "3   chastity 10.57    good 1.95   surrender 2.98\n",
      "Topic 4:\n",
      "                LSA          LDA             NNMF\n",
      "4          key 23.3    like 2.63         key 4.97\n",
      "4  encryption 14.16      don 2.5        chip 3.09\n",
      "4        chip 14.12    does 2.41  encryption 2.66\n",
      "4      clipper 12.1    know 2.31     clipper 2.34\n",
      "4  government 11.75    just 2.18        keys 2.09\n",
      "4         use 10.87   think 2.06  government 1.55\n",
      "4        keys 10.54  people 1.93      escrow 1.46\n",
      "4          law 8.48     use 1.89   algorithm 1.25\n",
      "4       public 8.37  thanks 1.75         use 1.17\n",
      "4         file 7.92    good 1.64         law 1.09\n",
      "Topic 5:\n",
      "               LSA          LDA             NNMF\n",
      "5      drive 31.16    just 3.24       drive 7.08\n",
      "5       scsi 16.31    like 2.81        disk 2.21\n",
      "5        hard 10.6     don 2.67        hard 2.03\n",
      "5     drives 10.25    know 2.59      drives 1.96\n",
      "5        disk 9.82   think 2.45      floppy 1.55\n",
      "5  controller 9.71  people 2.36        scsi 1.52\n",
      "5         ide 9.39    does 2.12         ide 1.27\n",
      "5        chip 8.51    good 2.02  controller 1.15\n",
      "5         bus 7.93  thanks 1.93        boot 0.84\n",
      "5        card 7.56     time 1.9     problem 0.83\n",
      "Topic 6:\n",
      "           LSA          LDA          NNMF\n",
      "6    god 20.85    know 2.43     game 2.76\n",
      "6    game 15.5     don 2.42     team 2.44\n",
      "6    key 13.36    just 2.27    games 1.85\n",
      "6  games 12.99    like 2.21     year 1.68\n",
      "6   team 12.88   think 2.18  players 1.36\n",
      "6    mail 8.92    does 2.13   season 1.27\n",
      "6    chip 8.87    good 2.09      play 1.2\n",
      "6      00 8.76     use 1.99   hockey 1.18\n",
      "6     edu 8.15  thanks 1.95      win 0.99\n",
      "6    year 8.13     edu 1.77   league 0.92\n",
      "Topic 7:\n",
      "             LSA          LDA              NNMF\n",
      "7    thanks 35.3    know 2.65       thanks 7.39\n",
      "7     know 25.62    does 2.58      advance 2.89\n",
      "7      does 20.1    like 2.55           hi 2.47\n",
      "7     mail 17.01     just 2.4         mail 2.23\n",
      "7  advance 11.95     don 2.36         know 2.07\n",
      "7  looking 11.01    think 2.2      looking 1.93\n",
      "7     info 10.59     use 2.16         does 1.72\n",
      "7        hi 9.54  thanks 2.04         help 1.71\n",
      "7     email 8.96  people 1.89         info 1.62\n",
      "7   anybody 8.37    good 1.68  appreciated 1.47\n",
      "Topic 8:\n",
      "                LSA          LDA         NNMF\n",
      "8          00 13.87     don 3.84     car 3.85\n",
      "8         new 11.88  people 3.75     bike 1.1\n",
      "8         edu 11.75    just 3.66      new 0.9\n",
      "8       space 10.18    know 3.66    cars 0.87\n",
      "8         sale 9.99     god 3.32    good 0.86\n",
      "8       israel 8.48    like 3.17    like 0.79\n",
      "8           10 8.21   think 2.81  engine 0.69\n",
      "8         mail 7.96     use 2.51    just 0.65\n",
      "8        email 7.86     does 2.5    miles 0.6\n",
      "8  information 7.17     did 2.38  dealer 0.56\n",
      "Topic 9:\n",
      "           LSA           LDA          NNMF\n",
      "9  drive 18.18    just 87.12     card 5.58\n",
      "9    file 9.54    like 86.58    video 2.68\n",
      "9  thanks 9.05    know 85.05  monitor 1.99\n",
      "9    team 8.29     don 85.02  drivers 1.56\n",
      "9    scsi 8.03  people 77.21      vga 1.51\n",
      "9   files 7.87   think 72.41      bus 1.39\n",
      "9     game 7.6    does 71.86    cards 1.33\n",
      "9    disk 5.58     use 63.08  windows 1.26\n",
      "9  drives 5.09  thanks 61.47    driver 1.2\n",
      "9    hard 4.88    good 60.71    color 1.17\n",
      "Topic 10:\n",
      "                LSA          LDA             NNMF\n",
      "10       card 18.74     know 2.9      people 3.72\n",
      "10       does 11.78    like 2.85  government 1.91\n",
      "10     israel 10.48    just 2.68         gun 1.36\n",
      "10        game 9.73    does 2.59     armenian 1.3\n",
      "10       video 9.37  thanks 2.45         don 1.22\n",
      "10        team 7.45     don 2.43       right 1.13\n",
      "10        jews 7.45     use 2.08         law 1.09\n",
      "10      people 7.33   think 2.03       think 1.08\n",
      "10  government 7.05     new 1.97   armenians 1.05\n",
      "10     israeli 6.76     edu 1.95     turkish 0.96\n",
      "Topic 11:\n",
      "             LSA          LDA          NNMF\n",
      "11     car 17.79    like 2.45   windows 5.4\n",
      "11  windows 16.7    just 2.17      dos 2.58\n",
      "11      dos 9.51     know 2.1       ms 1.01\n",
      "11       00 8.87   think 1.99     file 1.01\n",
      "11   thanks 5.92      don 1.9  version 0.92\n",
      "11    drive 5.91   people 1.9     files 0.9\n",
      "11     bike 5.44      use 1.8  running 0.89\n",
      "11    price 5.14    does 1.75   thanks 0.83\n",
      "11      new 5.11    good 1.73       use 0.8\n",
      "11     file 5.06  thanks 1.69  drivers 0.77\n",
      "Topic 12:\n",
      "             LSA          LDA              NNMF\n",
      "12    does 16.96    like 2.15       window 5.05\n",
      "12  window 15.34    just 2.13        motif 1.42\n",
      "12      car 15.1    know 2.08       server 1.36\n",
      "12  israel 10.81  people 1.83  application 1.28\n",
      "12     jews 6.25     don 1.79      problem 1.22\n",
      "12  israeli 6.22   think 1.76      manager 1.18\n",
      "12  problem 6.07  thanks 1.68       windows 1.1\n",
      "12      new 5.51    does 1.67      program 1.04\n",
      "12   server 5.36     use 1.64      display 0.99\n",
      "12     motif 5.3     good 1.6        using 0.97\n",
      "Topic 13:\n",
      "             LSA          LDA          NNMF\n",
      "13     don 21.65    like 2.79    space 4.17\n",
      "13      00 13.02    just 2.69     nasa 1.69\n",
      "13   think 12.08     don 2.42  shuttle 0.87\n",
      "13     sale 8.51    know 2.38   launch 0.85\n",
      "13      edu 7.86   think 2.26  program 0.76\n",
      "13    offer 6.84    does 2.22    orbit 0.71\n",
      "13     know 6.68  people 2.16     data 0.69\n",
      "13  shipping 6.6  thanks 2.03     moon 0.68\n",
      "13     want 6.58    good 2.03    earth 0.67\n",
      "13   people 6.43     god 1.99     like 0.63\n",
      "Topic 14:\n",
      "             LSA          LDA          NNMF\n",
      "14  israel 13.91    know 2.57     does 6.16\n",
      "14     does 12.8     don 2.54     know 5.14\n",
      "14   space 12.42    just 2.31   thanks 1.68\n",
      "14     know 7.92  thanks 2.29      don 1.47\n",
      "14  israeli 7.65    like 2.11     like 1.38\n",
      "14     just 6.34   think 1.91  anybody 1.37\n",
      "14     jews 6.21    does 1.88     just 1.14\n",
      "14     nasa 5.18     new 1.66   people 1.06\n",
      "14     arab 4.94    time 1.62      use 0.93\n",
      "14      car 4.45     use 1.56      god 0.93\n",
      "Topic 15:\n",
      "                LSA          LDA           NNMF\n",
      "15       does 25.43    like 2.92    israel 5.03\n",
      "15       know 18.82     just 2.9   israeli 2.67\n",
      "15          00 7.62    know 2.82      jews 2.27\n",
      "15         gun 6.18  people 2.72      arab 1.71\n",
      "15       space 5.42     don 2.67     arabs 1.17\n",
      "15         don 5.14   think 2.45    jewish 1.04\n",
      "15          use 4.9     use 2.26   lebanese 1.0\n",
      "15  government 4.75     does 2.2   lebanon 0.97\n",
      "15     anybody 3.68     edu 2.16     peace 0.96\n",
      "15      people 3.53    good 2.05  israelis 0.86\n",
      "Topic 16:\n",
      "             LSA           LDA           NNMF\n",
      "16    scsi 14.01  people 11.31        00 5.22\n",
      "16       edu 9.6     don 10.58         10 1.4\n",
      "16      car 8.35    like 10.46      sale 1.27\n",
      "16     list 7.26    just 10.41       new 1.18\n",
      "16      com 7.25     know 9.76        50 1.16\n",
      "16      bus 6.84    think 9.29        20 1.06\n",
      "16  deleted 6.38     does 8.65  shipping 1.02\n",
      "16       bit 5.7      use 8.38        15 0.98\n",
      "16     bike 5.56     time 8.22     price 0.98\n",
      "16    stuff 5.45     good 7.38        25 0.87\n",
      "Topic 17:\n",
      "           LSA          LDA             NNMF\n",
      "17   use 16.34      ax 5.58        scsi 6.42\n",
      "17     car 9.8    like 3.71         ide 2.04\n",
      "17     edu 9.6    know 3.57       drive 1.75\n",
      "17    gun 8.64    just 3.24  controller 1.71\n",
      "17    law 7.93     don 3.07         bus 1.56\n",
      "17   right 7.6   think 2.91         isa 1.05\n",
      "17    com 6.85  people 2.83         bit 1.02\n",
      "17   file 6.57     edu 2.67          pc 0.92\n",
      "17  driver 5.3    does 2.64      drives 0.72\n",
      "17   good 5.08    good 2.52         mac 0.71\n",
      "Topic 18:\n",
      "              LSA          LDA            NNMF\n",
      "18      file 14.5    just 2.75       file 4.95\n",
      "18     just 13.63     like 2.3      files 3.37\n",
      "18      edu 11.11  people 2.26    program 1.82\n",
      "18     know 10.28    know 2.23     windows 1.8\n",
      "18       com 9.25     don 2.03        ftp 1.66\n",
      "18       ftp 7.59    good 2.02        use 1.09\n",
      "18     files 6.63   think 2.01  directory 1.04\n",
      "18  graphics 5.46    does 1.87     format 1.02\n",
      "18      does 5.45     use 1.82      image 0.99\n",
      "18      bike 4.98     edu 1.75        dos 0.96\n",
      "Topic 19:\n",
      "             LSA              LDA          NNMF\n",
      "19     com 14.26      gordon 5.12      edu 3.04\n",
      "19     edu 11.22         geb 5.04     mail 2.52\n",
      "19    drive 7.86         dsl 4.98      com 2.03\n",
      "19    mouse 6.74    chastity 4.98     list 1.83\n",
      "19     card 6.62       n3jxp 4.98  address 1.56\n",
      "19      car 6.21    shameful 4.97     send 1.45\n",
      "19     list 6.06       cadre 4.96    email 1.39\n",
      "19  drivers 5.85   intellect 4.93   thanks 1.09\n",
      "19  windows 5.82  skepticism 4.92      like 1.0\n",
      "19   window 5.48        pitt 4.91     know 0.95\n"
     ]
    }
   ],
   "source": [
    "for topic in range(ntopics):\n",
    "    print('Topic {}:'.format(topic))\n",
    "    print(topwords.loc[topic])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# results\n",
    "- nmf is by far the best\n",
    "- nmf topics are consistently related to the newsgroups\n",
    "- LDA is the worst.\n",
    "- LDA topics can not be interpreted\n",
    "- Many LDA topics are duplicates\n",
    "- LSA is only slightly better than LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
