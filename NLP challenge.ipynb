{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sklearn\n",
    "import spacy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "from collections import Counter\n",
    "import nltk\n",
    "from sklearn import ensemble\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from nltk.corpus import gutenberg, stopwords\n",
    "from pandas.io.json import json_normalize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import Normalizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "yelp_reviews = pd.read_csv('yelp_labelled.txt', delimiter='\\t')\n",
    "amz_reviews = pd.read_csv('amazon_cells_labelled.txt', delimiter='\\t')\n",
    "imdb_reviews = pd.read_csv('imdb_labelled.txt', delimiter='\\t')\n",
    "\n",
    "#cleaning imdb reviews. There is extra white space at the end of every review.\n",
    "imdb_reviews['review'] = imdb_reviews['review'].apply(lambda x: x.strip())\n",
    "\n",
    "#classifying review websites\n",
    "yelp_reviews['website'] = 0\n",
    "amz_reviews['website'] = 1\n",
    "imdb_reviews['website'] = 2\n",
    "\n",
    "reviews_df = pd.concat([yelp_reviews, amz_reviews, imdb_reviews])\n",
    "reviews_df = reviews_df.set_index(np.arange(len(reviews_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>website</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Wow... Loved this place.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Crust is not good.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Not tasty and the texture was just nasty.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Stopped by during the late May bank holiday of...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>The selection on the menu was great and so wer...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2743</td>\n",
       "      <td>I just got bored watching Jessice Lange take h...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2744</td>\n",
       "      <td>Unfortunately, any virtue in this film's produ...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2745</td>\n",
       "      <td>In a word, it is embarrassing.</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2746</td>\n",
       "      <td>Exceptionally bad!</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2747</td>\n",
       "      <td>All in all its an insult to one's intelligence...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2748 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 review  sentiment  website\n",
       "0                              Wow... Loved this place.          1        0\n",
       "1                                    Crust is not good.          0        0\n",
       "2             Not tasty and the texture was just nasty.          0        0\n",
       "3     Stopped by during the late May bank holiday of...          1        0\n",
       "4     The selection on the menu was great and so wer...          1        0\n",
       "...                                                 ...        ...      ...\n",
       "2743  I just got bored watching Jessice Lange take h...          0        2\n",
       "2744  Unfortunately, any virtue in this film's produ...          0        2\n",
       "2745                     In a word, it is embarrassing.          0        2\n",
       "2746                                 Exceptionally bad!          0        2\n",
       "2747  All in all its an insult to one's intelligence...          0        2\n",
       "\n",
       "[2748 rows x 3 columns]"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_doc = ''\n",
    "\n",
    "for review in reviews_df['review']:\n",
    "    reviews_doc += review + ' '\n",
    "\n",
    "reviews_doc = reviews_doc.strip()\n",
    "\n",
    "reviews_doc = nlp(reviews_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bow(text):\n",
    "    all_words = [token.lemma_ for token in text if token.is_punct == False and token.is_stop == False]\n",
    "    \n",
    "    return [item[0] for item in Counter(all_words).most_common() if item[1] > 2]\n",
    "\n",
    "def bop(text):\n",
    "    all_words = [token.lemma_ for token in text if token.is_punct == True]\n",
    "    \n",
    "    return [item[0] for item in Counter(all_words).most_common() if item[1] > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_df['review'] = reviews_df['review'].apply(lambda x: nlp(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating features using BoW plus other features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features(reviews, tfidf=False):\n",
    "    \n",
    "    #common words and puncuation in all the reviews\n",
    "    common_words = bow(reviews_doc)\n",
    "    common_punct = bop(reviews_doc)\n",
    "    \n",
    "    df= pd.DataFrame()\n",
    "    \n",
    "    df['review'] = reviews['review']\n",
    "    \n",
    "    if tfidf == False:\n",
    "        \n",
    "        def words(review):\n",
    "\n",
    "            words = [token.lemma_ for token in review\n",
    "                     if token.is_punct == False\n",
    "                     and token.is_stop == False\n",
    "                     and token.lemma_ in common_words]\n",
    "            return Counter(words)\n",
    "\n",
    "        df['words'] = df['review'].apply(lambda x: words(x))\n",
    "        \n",
    "        word_data = list(df['words'])\n",
    "        word_data = pd.DataFrame(json_normalize(word_data))\n",
    "        def rename_cols(x):\n",
    "            return '{}_word'.format(x)\n",
    "        word_data = word_data.rename(lambda x: rename_cols(x), axis='columns')\n",
    "    \n",
    "    else:\n",
    "    \n",
    "        reviews_list = []\n",
    "\n",
    "        for review in df['review']:\n",
    "            reviews_list.append(review.text)\n",
    "\n",
    "        vectorizer = TfidfVectorizer(max_df=0.5, # drop words that occur in more than half the paragraphs\n",
    "                                     min_df=30, # only use words that appear at least three times\n",
    "                                     stop_words='english', \n",
    "                                     lowercase=True, #convert everything to lower case\n",
    "                                     use_idf=True,#we definitely want to use inverse document frequencies in our weighting\n",
    "                                     norm=u'l2', #Applies a correction factor so that longer reviews and shorter reviews \n",
    "                                                 #get treated equally\n",
    "                                     smooth_idf=True #Adds 1 to all document frequencies, as if an extra document existed that\n",
    "                                                    #used every word once.Prevents divide-by-zero errors\n",
    "                                    )\n",
    "\n",
    "        #Applying the vectorizer\n",
    "        reviews_tfidf = vectorizer.fit_transform(reviews_list)\n",
    "\n",
    "        #Reshapes the vectorizer output into something people can read\n",
    "        reviews_csr = reviews_tfidf.tocsr()\n",
    "\n",
    "        #number of reviews\n",
    "        n = reviews_csr.shape[0]\n",
    "        #A list of dictionaries, one per paragraph\n",
    "        tfidf_by_review = [{} for _ in range(0,n)]\n",
    "        #List of features\n",
    "        terms = vectorizer.get_feature_names()\n",
    "        #for each paragraph, lists the feature words and their tf-idf scores\n",
    "        for i, j in zip(*reviews_csr.nonzero()):\n",
    "            tfidf_by_review[i][terms[j]] = reviews_csr[i, j]\n",
    "            \n",
    "        df['words'] = tfidf_by_review\n",
    "        word_data = pd.DataFrame(json_normalize(tfidf_by_review))\n",
    "        def rename_cols(x):\n",
    "            return '{}_tfidf'.format(x)\n",
    "        word_data = word_data.rename(lambda x: rename_cols(x), axis='columns')\n",
    "    \n",
    "    def pos(review):\n",
    "        pos = [token.pos_ for token in review if token.is_punct == False and token.is_stop == False]\n",
    "        return Counter(pos)\n",
    "    \n",
    "    df['pos'] = df['review'].apply(lambda x: pos(x))\n",
    "    \n",
    "    pos_data = list(df['pos'])\n",
    "    pos_data = pd.DataFrame(json_normalize(pos_data))\n",
    "    def rename_cols(x):\n",
    "        return '{}_pos'.format(x)\n",
    "    pos_data = pos_data.rename(lambda x: rename_cols(x), axis='columns')\n",
    "    \n",
    "    \n",
    "    def dep(review):\n",
    "        dep = [token.dep_ for token in review if token.is_punct == False and token.is_stop == False]\n",
    "        return Counter(dep)\n",
    "    \n",
    "    df['dependencies'] = df['review'].apply(lambda x: dep(x))\n",
    "    \n",
    "    dep_data = list(df['dependencies'])\n",
    "    dep_data = pd.DataFrame(json_normalize(dep_data))\n",
    "    def rename_cols(x):\n",
    "        return '{}_dep'.format(x)\n",
    "    dep_data = dep_data.rename(lambda x: rename_cols(x), axis='columns')\n",
    "    \n",
    "    def punct(review):\n",
    "        punct = [token.text for token in review if token.is_punct == True and token.lemma_ in common_punct]\n",
    "        return Counter(punct)\n",
    "    \n",
    "    df['punct'] = df['review'].apply(lambda x: punct(x))\n",
    "    \n",
    "    punct_data = list(df['punct'])\n",
    "    punct_data = pd.DataFrame(json_normalize(punct_data))\n",
    "    def rename_cols(x):\n",
    "        return '{}_punct'.format(x)\n",
    "    punct_data = punct_data.rename(lambda x: rename_cols(x), axis='columns')\n",
    "    \n",
    "    df['review_length'] = df['review'].apply(lambda x: len(x))\n",
    "    \n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "    df['compound_sentiment_score'] = df['review'].apply(lambda x: analyzer.polarity_scores(x.text)['compound'])\n",
    "    df['pos_sentiment_score'] = df['review'].apply(lambda x: analyzer.polarity_scores(x.text)['pos'])\n",
    "    df['neg_sentiment_score'] = df['review'].apply(lambda x: analyzer.polarity_scores(x.text)['neg'])\n",
    "    \n",
    "    df = pd.concat([df, word_data, pos_data, dep_data, punct_data], axis=1)\n",
    "    \n",
    "    df['sentiment'] = reviews['sentiment']\n",
    "    df['website'] = reviews['website']\n",
    "    \n",
    "    df.fillna(0, inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>words</th>\n",
       "      <th>pos</th>\n",
       "      <th>dependencies</th>\n",
       "      <th>punct</th>\n",
       "      <th>review_length</th>\n",
       "      <th>compound_sentiment_score</th>\n",
       "      <th>pos_sentiment_score</th>\n",
       "      <th>neg_sentiment_score</th>\n",
       "      <th>wow_word</th>\n",
       "      <th>...</th>\n",
       "      <th>%_punct</th>\n",
       "      <th>*_punct</th>\n",
       "      <th>?_punct</th>\n",
       "      <th>:)_punct</th>\n",
       "      <th>--_punct</th>\n",
       "      <th>'_punct</th>\n",
       "      <th>......_punct</th>\n",
       "      <th>#_punct</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>website</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>(Wow, ..., Loved, this, place, .)</td>\n",
       "      <td>{'wow': 1, 'love': 1, 'place': 1}</td>\n",
       "      <td>{'INTJ': 1, 'VERB': 1, 'NOUN': 1}</td>\n",
       "      <td>{'intj': 1, 'ROOT': 1, 'dobj': 1}</td>\n",
       "      <td>{'...': 1, '.': 1}</td>\n",
       "      <td>6</td>\n",
       "      <td>0.5994</td>\n",
       "      <td>0.565</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>(Crust, is, not, good, .)</td>\n",
       "      <td>{'good': 1}</td>\n",
       "      <td>{'NOUN': 1, 'ADJ': 1}</td>\n",
       "      <td>{'nsubj': 1, 'acomp': 1}</td>\n",
       "      <td>{'.': 1}</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.3412</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.445</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>(Not, tasty, and, the, texture, was, just, nas...</td>\n",
       "      <td>{'tasty': 1, 'texture': 1, 'nasty': 1}</td>\n",
       "      <td>{'ADJ': 2, 'NOUN': 1}</td>\n",
       "      <td>{'nsubj': 1, 'conj': 1, 'acomp': 1}</td>\n",
       "      <td>{'.': 1}</td>\n",
       "      <td>9</td>\n",
       "      <td>-0.5574</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.340</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>(Stopped, by, during, the, late, May, bank, ho...</td>\n",
       "      <td>{'stop': 1, 'late': 1, 'recommendation': 1, 'l...</td>\n",
       "      <td>{'VERB': 2, 'ADJ': 1, 'NOUN': 3, 'PROPN': 2}</td>\n",
       "      <td>{'ROOT': 1, 'amod': 1, 'compound': 3, 'pobj': ...</td>\n",
       "      <td>{'.': 1}</td>\n",
       "      <td>16</td>\n",
       "      <td>0.6908</td>\n",
       "      <td>0.322</td>\n",
       "      <td>0.093</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>(The, selection, on, the, menu, was, great, an...</td>\n",
       "      <td>{'selection': 1, 'menu': 1, 'great': 1, 'price...</td>\n",
       "      <td>{'NOUN': 3, 'ADJ': 1}</td>\n",
       "      <td>{'nsubj': 2, 'pobj': 1, 'acomp': 1}</td>\n",
       "      <td>{'.': 1}</td>\n",
       "      <td>13</td>\n",
       "      <td>0.6249</td>\n",
       "      <td>0.272</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1219 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  \\\n",
       "0                  (Wow, ..., Loved, this, place, .)   \n",
       "1                          (Crust, is, not, good, .)   \n",
       "2  (Not, tasty, and, the, texture, was, just, nas...   \n",
       "3  (Stopped, by, during, the, late, May, bank, ho...   \n",
       "4  (The, selection, on, the, menu, was, great, an...   \n",
       "\n",
       "                                               words  \\\n",
       "0                  {'wow': 1, 'love': 1, 'place': 1}   \n",
       "1                                        {'good': 1}   \n",
       "2             {'tasty': 1, 'texture': 1, 'nasty': 1}   \n",
       "3  {'stop': 1, 'late': 1, 'recommendation': 1, 'l...   \n",
       "4  {'selection': 1, 'menu': 1, 'great': 1, 'price...   \n",
       "\n",
       "                                            pos  \\\n",
       "0             {'INTJ': 1, 'VERB': 1, 'NOUN': 1}   \n",
       "1                         {'NOUN': 1, 'ADJ': 1}   \n",
       "2                         {'ADJ': 2, 'NOUN': 1}   \n",
       "3  {'VERB': 2, 'ADJ': 1, 'NOUN': 3, 'PROPN': 2}   \n",
       "4                         {'NOUN': 3, 'ADJ': 1}   \n",
       "\n",
       "                                        dependencies               punct  \\\n",
       "0                  {'intj': 1, 'ROOT': 1, 'dobj': 1}  {'...': 1, '.': 1}   \n",
       "1                           {'nsubj': 1, 'acomp': 1}            {'.': 1}   \n",
       "2                {'nsubj': 1, 'conj': 1, 'acomp': 1}            {'.': 1}   \n",
       "3  {'ROOT': 1, 'amod': 1, 'compound': 3, 'pobj': ...            {'.': 1}   \n",
       "4                {'nsubj': 2, 'pobj': 1, 'acomp': 1}            {'.': 1}   \n",
       "\n",
       "   review_length  compound_sentiment_score  pos_sentiment_score  \\\n",
       "0              6                    0.5994                0.565   \n",
       "1              5                   -0.3412                0.000   \n",
       "2              9                   -0.5574                0.000   \n",
       "3             16                    0.6908                0.322   \n",
       "4             13                    0.6249                0.272   \n",
       "\n",
       "   neg_sentiment_score  wow_word  ...  %_punct  *_punct  ?_punct  :)_punct  \\\n",
       "0                0.000       1.0  ...      0.0      0.0      0.0       0.0   \n",
       "1                0.445       0.0  ...      0.0      0.0      0.0       0.0   \n",
       "2                0.340       0.0  ...      0.0      0.0      0.0       0.0   \n",
       "3                0.093       0.0  ...      0.0      0.0      0.0       0.0   \n",
       "4                0.000       0.0  ...      0.0      0.0      0.0       0.0   \n",
       "\n",
       "   --_punct  '_punct  ......_punct  #_punct  sentiment  website  \n",
       "0       0.0      0.0           0.0      0.0          1        0  \n",
       "1       0.0      0.0           0.0      0.0          0        0  \n",
       "2       0.0      0.0           0.0      0.0          0        0  \n",
       "3       0.0      0.0           0.0      0.0          1        0  \n",
       "4       0.0      0.0           0.0      0.0          1        0  \n",
       "\n",
       "[5 rows x 1219 columns]"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_features = features(reviews_df, tfidf=False)\n",
    "model_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = model_features.drop(['review', 'sentiment', 'words', 'pos', 'punct', 'dependencies', 'website'], axis=1)\n",
    "Y = model_features['sentiment']\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set score: 0.8971792538671519\n",
      "test set score: 0.8363636363636363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(penalty='l2')\n",
    "\n",
    "lr.fit(X_train, Y_train)\n",
    "\n",
    "print('train set score: {}'.format(lr.score(X_train, Y_train)))\n",
    "print('test set score: {}'.format(lr.score(X_test, Y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set score: 0.8685168334849863\n",
      "test set score: 0.8290909090909091\n"
     ]
    }
   ],
   "source": [
    "nb = BernoulliNB()\n",
    "\n",
    "nb.fit(X_train, Y_train)\n",
    "\n",
    "print('train set score: {}'.format(nb.score(X_train, Y_train)))\n",
    "print('test set score: {}'.format(nb.score(X_test, Y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating features using tfidf plus other features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>words</th>\n",
       "      <th>pos</th>\n",
       "      <th>dependencies</th>\n",
       "      <th>punct</th>\n",
       "      <th>review_length</th>\n",
       "      <th>compound_sentiment_score</th>\n",
       "      <th>pos_sentiment_score</th>\n",
       "      <th>neg_sentiment_score</th>\n",
       "      <th>place_tfidf</th>\n",
       "      <th>...</th>\n",
       "      <th>%_punct</th>\n",
       "      <th>*_punct</th>\n",
       "      <th>?_punct</th>\n",
       "      <th>:)_punct</th>\n",
       "      <th>--_punct</th>\n",
       "      <th>'_punct</th>\n",
       "      <th>......_punct</th>\n",
       "      <th>#_punct</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>website</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>(Wow, ..., Loved, this, place, .)</td>\n",
       "      <td>{'place': 1.0}</td>\n",
       "      <td>{'INTJ': 1, 'VERB': 1, 'NOUN': 1}</td>\n",
       "      <td>{'intj': 1, 'ROOT': 1, 'dobj': 1}</td>\n",
       "      <td>{'...': 1, '.': 1}</td>\n",
       "      <td>6</td>\n",
       "      <td>0.5994</td>\n",
       "      <td>0.565</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>(Crust, is, not, good, .)</td>\n",
       "      <td>{'good': 1.0}</td>\n",
       "      <td>{'NOUN': 1, 'ADJ': 1}</td>\n",
       "      <td>{'nsubj': 1, 'acomp': 1}</td>\n",
       "      <td>{'.': 1}</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.3412</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.445</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>(Not, tasty, and, the, texture, was, just, nas...</td>\n",
       "      <td>{'just': 1.0}</td>\n",
       "      <td>{'ADJ': 2, 'NOUN': 1}</td>\n",
       "      <td>{'nsubj': 1, 'conj': 1, 'acomp': 1}</td>\n",
       "      <td>{'.': 1}</td>\n",
       "      <td>9</td>\n",
       "      <td>-0.5574</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.340</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>(Stopped, by, during, the, late, May, bank, ho...</td>\n",
       "      <td>{}</td>\n",
       "      <td>{'VERB': 2, 'ADJ': 1, 'NOUN': 3, 'PROPN': 2}</td>\n",
       "      <td>{'ROOT': 1, 'amod': 1, 'compound': 3, 'pobj': ...</td>\n",
       "      <td>{'.': 1}</td>\n",
       "      <td>16</td>\n",
       "      <td>0.6908</td>\n",
       "      <td>0.322</td>\n",
       "      <td>0.093</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>(The, selection, on, the, menu, was, great, an...</td>\n",
       "      <td>{'great': 1.0}</td>\n",
       "      <td>{'NOUN': 3, 'ADJ': 1}</td>\n",
       "      <td>{'nsubj': 2, 'pobj': 1, 'acomp': 1}</td>\n",
       "      <td>{'.': 1}</td>\n",
       "      <td>13</td>\n",
       "      <td>0.6249</td>\n",
       "      <td>0.272</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 151 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review           words  \\\n",
       "0                  (Wow, ..., Loved, this, place, .)  {'place': 1.0}   \n",
       "1                          (Crust, is, not, good, .)   {'good': 1.0}   \n",
       "2  (Not, tasty, and, the, texture, was, just, nas...   {'just': 1.0}   \n",
       "3  (Stopped, by, during, the, late, May, bank, ho...              {}   \n",
       "4  (The, selection, on, the, menu, was, great, an...  {'great': 1.0}   \n",
       "\n",
       "                                            pos  \\\n",
       "0             {'INTJ': 1, 'VERB': 1, 'NOUN': 1}   \n",
       "1                         {'NOUN': 1, 'ADJ': 1}   \n",
       "2                         {'ADJ': 2, 'NOUN': 1}   \n",
       "3  {'VERB': 2, 'ADJ': 1, 'NOUN': 3, 'PROPN': 2}   \n",
       "4                         {'NOUN': 3, 'ADJ': 1}   \n",
       "\n",
       "                                        dependencies               punct  \\\n",
       "0                  {'intj': 1, 'ROOT': 1, 'dobj': 1}  {'...': 1, '.': 1}   \n",
       "1                           {'nsubj': 1, 'acomp': 1}            {'.': 1}   \n",
       "2                {'nsubj': 1, 'conj': 1, 'acomp': 1}            {'.': 1}   \n",
       "3  {'ROOT': 1, 'amod': 1, 'compound': 3, 'pobj': ...            {'.': 1}   \n",
       "4                {'nsubj': 2, 'pobj': 1, 'acomp': 1}            {'.': 1}   \n",
       "\n",
       "   review_length  compound_sentiment_score  pos_sentiment_score  \\\n",
       "0              6                    0.5994                0.565   \n",
       "1              5                   -0.3412                0.000   \n",
       "2              9                   -0.5574                0.000   \n",
       "3             16                    0.6908                0.322   \n",
       "4             13                    0.6249                0.272   \n",
       "\n",
       "   neg_sentiment_score  place_tfidf  ...  %_punct  *_punct  ?_punct  :)_punct  \\\n",
       "0                0.000          1.0  ...      0.0      0.0      0.0       0.0   \n",
       "1                0.445          0.0  ...      0.0      0.0      0.0       0.0   \n",
       "2                0.340          0.0  ...      0.0      0.0      0.0       0.0   \n",
       "3                0.093          0.0  ...      0.0      0.0      0.0       0.0   \n",
       "4                0.000          0.0  ...      0.0      0.0      0.0       0.0   \n",
       "\n",
       "   --_punct  '_punct  ......_punct  #_punct  sentiment  website  \n",
       "0       0.0      0.0           0.0      0.0          1        0  \n",
       "1       0.0      0.0           0.0      0.0          0        0  \n",
       "2       0.0      0.0           0.0      0.0          0        0  \n",
       "3       0.0      0.0           0.0      0.0          1        0  \n",
       "4       0.0      0.0           0.0      0.0          1        0  \n",
       "\n",
       "[5 rows x 151 columns]"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_features = features(reviews_df, tfidf=True)\n",
    "model_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = model_features.drop(['review', 'sentiment', 'words', 'pos', 'punct', 'dependencies', 'website'], axis=1)\n",
    "Y = model_features['sentiment']\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set score: 0.8466787989080983\n",
      "test set score: 0.8327272727272728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(penalty='l2')\n",
    "\n",
    "lr.fit(X_train, Y_train)\n",
    "\n",
    "print('train set score: {}'.format(lr.score(X_train, Y_train)))\n",
    "print('test set score: {}'.format(lr.score(X_test, Y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set score: 0.8303002729754322\n",
      "test set score: 0.8272727272727273\n"
     ]
    }
   ],
   "source": [
    "nb = BernoulliNB()\n",
    "\n",
    "nb.fit(X_train, Y_train)\n",
    "\n",
    "print('train set score: {}'.format(nb.score(X_train, Y_train)))\n",
    "print('test set score: {}'.format(nb.score(X_test, Y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set score: 0.8466787989080983\n",
      "test set score: 0.8327272727272728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "\n",
    "lr.fit(X_train, Y_train)\n",
    "\n",
    "print('train set score: {}'.format(lr.score(X_train, Y_train)))\n",
    "print('test set score: {}'.format(lr.score(X_test, Y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set score: 0.5118289353958144\n",
      "test set score: 0.49636363636363634\n"
     ]
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "dc = DummyClassifier(strategy=\"stratified\")\n",
    "\n",
    "dc.fit(X_train, Y_train)\n",
    "\n",
    "print('train set score: {}'.format(dc.score(X_train, Y_train)))\n",
    "print('test set score: {}'.format(dc.score(X_test, Y_test)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
