{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "yelp_df = pd.read_csv('yelp_labelled.txt', delimiter='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "yelp_df['sentiment'] = yelp_df['review'].str[-1]\n",
    "yelp_df['sentiment'] = pd.to_numeric(yelp_df['sentiment'])\n",
    "yelp_df['review'] = yelp_df['review'].str[:-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Wow... Loved this place</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Crust is not good</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Not tasty and the texture was just nasty</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Stopped by during the late May bank holiday of...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>The selection on the menu was great and so wer...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0                            Wow... Loved this place          1\n",
       "1                                  Crust is not good          0\n",
       "2           Not tasty and the texture was just nasty          0\n",
       "3  Stopped by during the late May bank holiday of...          1\n",
       "4  The selection on the menu was great and so wer...          1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Version 1 (original) - Positive, neutral, and negative keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_keywords = ['the', 'not', \"don't\", 'good', 'would', 'never', 'time', 'ever', 'badly',\n",
    "                      'minutes', \"won't\", 'bad', 'much', 'again', 'worst', 'disappointed', \n",
    "                      'really', 'slow', 'waited', 'wait', 'bland', 'flavor', 'experience', 'best', \n",
    "                      'terrible', 'rude', 'cold', 'taste', 'overpriced', 'poor', 'mediocre', \n",
    "                      'management', 'off', 'impressed', 'money', 'horrible', 'sick', 'waiter', 'tasted', 'nasty', \n",
    "                      'great', 'angry', 'honestly', 'care', 'disgusted', 'recommended', 'not worth', 'amazing', \n",
    "                      'liked', 'hour', 'dirty', 'clean', 'unfortunately', 'worse', 'friendly', 'love', 'loved', \n",
    "                      'absolutely', 'excellent', 'recommend', 'wonderful', 'delicious', 'fantastic', 'incredible', \n",
    "                      'nice', 'disappointment', 'tasteless', 'enjoyed', 'waste', 'authentic', 'homemade', 'worse',\n",
    "                     'pleasant', 'pleased', 'outstanding', 'generous', 'insulted', 'soggy', 'lacking', 'sad',\n",
    "                     'stale', 'helpful', 'sucks', 'beautiful', 'i', 'very', 'food', 'rotten', 'spoiled', 'stomach',\n",
    "                     'only', 'fresh']\n",
    "sentiment_phrases_2word = ['be back', 'i would', \"wont' be\", 'very good', 'i love', 'would not', \n",
    "                    'so good', 'not good', 'here again', 'will never', 'good food', 'great place', 'great food', \n",
    "                     'really good', 'customer service', '5 stars', 'at best', 'not like', 'at all', 'thumbs up',\n",
    "                    'great service', 'definitely not', 'definitely will', 'highly recommend', 'highly recommended',\n",
    "                          'very disappointing', 'not pleasant', 'not pleased', 'not helpful', 'good quality',\n",
    "                          'bad quality', 'not fresh', 'not nice']\n",
    "\n",
    "sentiment_phrases_3word = [\"won't be back\", 'will be back', \"won't be going\", 'will never ever', \n",
    "                           \"won't be disappointed\", 'back anytime soon', 'would not recommend', 'service was slow', ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in sentiment_keywords:\n",
    "    yelp_df[word] = yelp_df['review'].str.contains(word, case=False)\n",
    "\n",
    "for phrase in sentiment_phrases_2word:\n",
    "    yelp_df[phrase] = yelp_df['review'].str.contains(phrase, case=False)\n",
    "\n",
    "for phrase in sentiment_phrases_3word:\n",
    "    yelp_df[phrase] = yelp_df['review'].str.contains(phrase, case=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model correctly classified 82.0% of the training set.\n",
      "This model correctly classified 76.0% of the test set.\n",
      "-----------------------------------------------------------------------\n",
      "88.0% of the negative review predictions were correct in the training set.\n",
      "77.0% of the positive review predictions were correct in the training set.\n",
      "-----------------------------------------------------------------------\n",
      "83.0% of the negative review predictions were correct in the test set.\n",
      "71.0% of the positive review predictions were correct in the test set.\n"
     ]
    }
   ],
   "source": [
    "data = yelp_df[sentiment_keywords + sentiment_phrases_2word + sentiment_phrases_3word]\n",
    "target = yelp_df['sentiment']\n",
    "\n",
    "X = data\n",
    "Y = target\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=.2, random_state=200)\n",
    "\n",
    "bnb = BernoulliNB()\n",
    "\n",
    "bnb.fit(X_train, Y_train)\n",
    "\n",
    "training_pred = bnb.predict(X_train)\n",
    "test_pred = bnb.predict(X_test)\n",
    "\n",
    "print('This model correctly classified {}% of the training set.'.format(100*round((Y_train == training_pred).sum()/800,2)))\n",
    "print('This model correctly classified {}% of the test set.'.format(100*round((Y_test == test_pred).sum()/200,2)))\n",
    "\n",
    "training_confusion_matrix = pd.crosstab(Y_train, training_pred)\n",
    "training_negative_reviews = training_confusion_matrix.iloc[0,0]\n",
    "training_false_negative_reviews = training_confusion_matrix.iloc[1,0]\n",
    "training_positive_reviews = training_confusion_matrix.iloc[1,1]\n",
    "training_false_positive_reviews = training_confusion_matrix.iloc[0,1]\n",
    "\n",
    "training_sensitivity = training_negative_reviews/(training_negative_reviews + training_false_negative_reviews)\n",
    "training_specificity = training_positive_reviews/(training_positive_reviews + training_false_positive_reviews)\n",
    "\n",
    "print('-----------------------------------------------------------------------')\n",
    "print('{}% of the negative review predictions were correct in the training set.'.format(round(training_sensitivity*100, 0)))\n",
    "print('{}% of the positive review predictions were correct in the training set.'.format(round(training_specificity*100, 0)))\n",
    "\n",
    "test_confusion_matrix = pd.crosstab(Y_test, test_pred)\n",
    "test_negative_reviews = test_confusion_matrix.iloc[0,0]\n",
    "test_false_negative_reviews = test_confusion_matrix.iloc[1,0]\n",
    "test_positive_reviews = test_confusion_matrix.iloc[1,1]\n",
    "test_false_positive_reviews = test_confusion_matrix.iloc[0,1]\n",
    "\n",
    "test_sensitivity = test_negative_reviews/(test_negative_reviews + test_false_negative_reviews)\n",
    "test_specificity = test_positive_reviews/(test_positive_reviews + test_false_positive_reviews)\n",
    "print('-----------------------------------------------------------------------')\n",
    "print('{}% of the negative review predictions were correct in the test set.'.format(round(test_sensitivity*100, 0)))\n",
    "print('{}% of the positive review predictions were correct in the test set.'.format(round(test_specificity*100, 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model seems to be slightly overfit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Version 2 - only negative keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_keywords = ['bad', 'worst', 'disappointed', 'slow', 'waited', 'wait', 'bland', 'slow', 'waited', 'wait',\n",
    "                      'bland', 'terrible', 'rude', 'cold', 'overpriced', 'poor', 'mediocre', 'horrible', 'sick',\n",
    "                      'nasty', 'angry', 'disgusted', 'amazing', 'hour', 'dirty', 'clean', 'unfortunately', 'worse']\n",
    "                        \n",
    "sentiment_phrases_2word = ['not worth', 'bad service', 'not good', 'not great', 'not tasty', 'no good', 'really bad', 'very bad'\n",
    "                          'not good', 'bad experience', 'horrible experience', 'not great', 'very disappointed',\n",
    "                          'not impressed']\n",
    "\n",
    "sentiment_phrases_3word = [\"won't be back\", \"won't be going\", 'will never ever', 'not very tasty'\n",
    "                           \"wont' be back anytime soon\", 'would not recommend', 'service was slow']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in sentiment_keywords:\n",
    "    yelp_df[word] = yelp_df['review'].str.contains(word, case=False)\n",
    "\n",
    "for phrase in sentiment_phrases_2word:\n",
    "    yelp_df[phrase] = yelp_df['review'].str.contains(phrase, case=False)\n",
    "\n",
    "for phrase in sentiment_phrases_3word:\n",
    "    yelp_df[phrase] = yelp_df['review'].str.contains(phrase, case=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = yelp_df[sentiment_keywords + sentiment_phrases_2word + sentiment_phrases_3word]\n",
    "target = yelp_df['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model correctly classified 66.0% of the training set.\n",
      "This model correctly classified 68.0% of the test set.\n",
      "---------------------------------------------------------\n",
      "89.0% of the negative review predictions were correct in the training set.\n",
      "61.0% of the positive review predictions were correct in the training set.\n",
      "-----------------------------------------------------------------------\n",
      "98.0% of the negative review predictions were correct in the test set.\n",
      "59.0% of the positive review predictions were correct in the test set.\n"
     ]
    }
   ],
   "source": [
    "X = data\n",
    "Y = target\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=.2, random_state=200)\n",
    "\n",
    "bnb = BernoulliNB()\n",
    "\n",
    "bnb.fit(X_train, Y_train)\n",
    "\n",
    "training_pred = bnb.predict(X_train)\n",
    "test_pred = bnb.predict(X_test)\n",
    "\n",
    "print('This model correctly classified {}% of the training set.'.format(100*round((Y_train == training_pred).sum()/800,2)))\n",
    "print('This model correctly classified {}% of the test set.'.format(100*round((Y_test == test_pred).sum()/200,2)))\n",
    "print('---------------------------------------------------------')\n",
    "\n",
    "training_confusion_matrix = pd.crosstab(Y_train, training_pred)\n",
    "training_negative_reviews = training_confusion_matrix.iloc[0,0]\n",
    "training_false_negative_reviews = training_confusion_matrix.iloc[1,0]\n",
    "training_positive_reviews = training_confusion_matrix.iloc[1,1]\n",
    "training_false_positive_reviews = training_confusion_matrix.iloc[0,1]\n",
    "\n",
    "training_sensitivity = training_negative_reviews/(training_negative_reviews + training_false_negative_reviews)\n",
    "training_specificity = training_positive_reviews/(training_positive_reviews + training_false_positive_reviews)\n",
    "\n",
    "print('{}% of the negative review predictions were correct in the training set.'.format(round(training_sensitivity*100, 0)))\n",
    "print('{}% of the positive review predictions were correct in the training set.'.format(round(training_specificity*100, 0)))\n",
    "\n",
    "test_confusion_matrix = pd.crosstab(Y_test, test_pred)\n",
    "test_negative_reviews = test_confusion_matrix.iloc[0,0]\n",
    "test_false_negative_reviews = test_confusion_matrix.iloc[1,0]\n",
    "test_positive_reviews = test_confusion_matrix.iloc[1,1]\n",
    "test_false_positive_reviews = test_confusion_matrix.iloc[0,1]\n",
    "\n",
    "test_sensitivity = test_negative_reviews/(test_negative_reviews + test_false_negative_reviews)\n",
    "test_specificity = test_positive_reviews/(test_positive_reviews + test_false_positive_reviews)\n",
    "print('-----------------------------------------------------------------------')\n",
    "print('{}% of the negative review predictions were correct in the test set.'.format(round(test_sensitivity*100, 0)))\n",
    "print('{}% of the positive review predictions were correct in the test set.'.format(round(test_specificity*100, 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results of version 2 model compared to original model\n",
    "- The model is no longer overfit\n",
    "- overall accuracy declined to 68% from 76%.\n",
    "- sensitivity increased to 91% from 84%. This means the negative keywords helped identify the negative reviews.\n",
    "- specificity decreased tp 60% from 74%. This means the negative keywords hindered indentifying the positive reviews."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Version 3 - Only positive keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_keywords = ['good', 'best', 'impressive', 'great', 'amazing', 'liked', 'clean', 'friendly', 'love', 'loved', \n",
    "                      'absolutely', 'excellent', 'recommend', 'wonderful', 'delicious', 'fantastic', 'incredible', \n",
    "                      'nice']\n",
    "sentiment_phrases_2word = ['best ever', 'so good', 'really great', 'very good', 'i love', 'would not', \n",
    "                           'good food', 'great place', 'great food', 'really good', 'customer service', '5 stars',\n",
    "                           'great service', 'definitely will', 'highly recommend', 'highly recommended']\n",
    "\n",
    "sentiment_phrases_3word = ['will be back', \"won't be disappointed\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in sentiment_keywords:\n",
    "    yelp_df[word] = yelp_df['review'].str.contains(word, case=False)\n",
    "\n",
    "for phrase in sentiment_phrases_2word:\n",
    "    yelp_df[phrase] = yelp_df['review'].str.contains(phrase, case=False)\n",
    "\n",
    "for phrase in sentiment_phrases_3word:\n",
    "    yelp_df[phrase] = yelp_df['review'].str.contains(phrase, case=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = yelp_df[sentiment_keywords + sentiment_phrases_2word + sentiment_phrases_3word]\n",
    "target = yelp_df['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model correctly classified 75.0% of the training set.\n",
      "This model correctly classified 72.0% of the test set.\n",
      "---------------------------------------------------------\n",
      "68.0% of the negative review predictions were correct in the training set.\n",
      "87.0% of the positive review predictions were correct in the training set.\n",
      "-----------------------------------------------------------------------\n",
      "68.0% of the negative review predictions were correct in the test set.\n",
      "85.0% of the positive review predictions were correct in the test set.\n"
     ]
    }
   ],
   "source": [
    "X = data\n",
    "Y = target\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=.2, random_state=200)\n",
    "\n",
    "bnb = BernoulliNB()\n",
    "\n",
    "bnb.fit(X_train, Y_train)\n",
    "\n",
    "training_pred = bnb.predict(X_train)\n",
    "test_pred = bnb.predict(X_test)\n",
    "\n",
    "print('This model correctly classified {}% of the training set.'.format(100*round((Y_train == training_pred).sum()/800,2)))\n",
    "print('This model correctly classified {}% of the test set.'.format(100*round((Y_test == test_pred).sum()/200,2)))\n",
    "print('---------------------------------------------------------')\n",
    "\n",
    "training_confusion_matrix = pd.crosstab(Y_train, training_pred)\n",
    "training_negative_reviews = training_confusion_matrix.iloc[0,0]\n",
    "training_false_negative_reviews = training_confusion_matrix.iloc[1,0]\n",
    "training_positive_reviews = training_confusion_matrix.iloc[1,1]\n",
    "training_false_positive_reviews = training_confusion_matrix.iloc[0,1]\n",
    "\n",
    "training_sensitivity = training_negative_reviews/(training_negative_reviews + training_false_negative_reviews)\n",
    "training_specificity = training_positive_reviews/(training_positive_reviews + training_false_positive_reviews)\n",
    "\n",
    "print('{}% of the negative review predictions were correct in the training set.'.format(round(training_sensitivity*100, 0)))\n",
    "print('{}% of the positive review predictions were correct in the training set.'.format(round(training_specificity*100, 0)))\n",
    "\n",
    "test_confusion_matrix = pd.crosstab(Y_test, test_pred)\n",
    "test_negative_reviews = test_confusion_matrix.iloc[0,0]\n",
    "test_false_negative_reviews = test_confusion_matrix.iloc[1,0]\n",
    "test_positive_reviews = test_confusion_matrix.iloc[1,1]\n",
    "test_false_positive_reviews = test_confusion_matrix.iloc[0,1]\n",
    "\n",
    "test_sensitivity = test_negative_reviews/(test_negative_reviews + test_false_negative_reviews)\n",
    "test_specificity = test_positive_reviews/(test_positive_reviews + test_false_positive_reviews)\n",
    "print('-----------------------------------------------------------------------')\n",
    "print('{}% of the negative review predictions were correct in the test set.'.format(round(test_sensitivity*100, 0)))\n",
    "print('{}% of the positive review predictions were correct in the test set.'.format(round(test_specificity*100, 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results of version 3 model compared to original model\n",
    "- The model is less overfit than the original\n",
    "- overall accuracy declined to 72% from 76%.\n",
    "- sensitivity decreased to 68% from 84%. This means the positive keywords hindered identifying the negative reviews.\n",
    "- specificity increased to 87% from 74%. This means the positive keywords helped in identifying the positive reviews."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Version 4 - Only phrases  (both positive and negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_phrases_2word = ['be back', 'i would', \"wont' be\", 'very good', 'i love', 'would not', \n",
    "                    'so good', 'not good', 'here again', 'will never', 'good food', 'great place', 'great food', \n",
    "                     'really good', 'customer service', '5 stars', 'at best', 'not like', 'at all', 'no good',\n",
    "                    'great service', 'definitely not', 'definitely will', 'highly recommend', 'highly recommended',\n",
    "                          \"definitely won't\"]\n",
    "\n",
    "sentiment_phrases_3word = ['not very good', \"won't be back\", 'will be back', \"won't be going\", 'will never ever', \n",
    "                           \"won't be disappointed\", 'back anytime soon', 'would not recommend', 'service was slow',\n",
    "                          'not so good', 'not good food', 'really great food', 'not great food', 'not be back',\n",
    "                          'not to like', 'bad customer service', 'great customer service']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for phrase in sentiment_phrases_2word:\n",
    "    yelp_df[phrase] = yelp_df['review'].str.contains(phrase, case=False)\n",
    "\n",
    "for phrase in sentiment_phrases_3word:\n",
    "    yelp_df[phrase] = yelp_df['review'].str.contains(phrase, case=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = yelp_df[sentiment_phrases_2word + sentiment_phrases_3word]\n",
    "target = yelp_df['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model correctly classified 56.00000000000001% of the training set.\n",
      "This model correctly classified 53.0% of the test set.\n",
      "---------------------------------------------------------\n",
      "86.0% of the negative review predictions were correct in the training set.\n",
      "54.0% of the positive review predictions were correct in the training set.\n",
      "-----------------------------------------------------------------------\n",
      "93.0% of the negative review predictions were correct in the test set.\n",
      "50.0% of the positive review predictions were correct in the test set.\n"
     ]
    }
   ],
   "source": [
    "X = data\n",
    "Y = target\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=.2, random_state=200)\n",
    "\n",
    "bnb = BernoulliNB()\n",
    "\n",
    "bnb.fit(X_train, Y_train)\n",
    "\n",
    "training_pred = bnb.predict(X_train)\n",
    "test_pred = bnb.predict(X_test)\n",
    "\n",
    "print('This model correctly classified {}% of the training set.'.format(100*round((Y_train == training_pred).sum()/800,2)))\n",
    "print('This model correctly classified {}% of the test set.'.format(100*round((Y_test == test_pred).sum()/200,2)))\n",
    "print('---------------------------------------------------------')\n",
    "\n",
    "training_confusion_matrix = pd.crosstab(Y_train, training_pred)\n",
    "training_negative_reviews = training_confusion_matrix.iloc[0,0]\n",
    "training_false_negative_reviews = training_confusion_matrix.iloc[1,0]\n",
    "training_positive_reviews = training_confusion_matrix.iloc[1,1]\n",
    "training_false_positive_reviews = training_confusion_matrix.iloc[0,1]\n",
    "\n",
    "training_sensitivity = training_negative_reviews/(training_negative_reviews + training_false_negative_reviews)\n",
    "training_specificity = training_positive_reviews/(training_positive_reviews + training_false_positive_reviews)\n",
    "\n",
    "print('{}% of the negative review predictions were correct in the training set.'.format(round(training_sensitivity*100, 0)))\n",
    "print('{}% of the positive review predictions were correct in the training set.'.format(round(training_specificity*100, 0)))\n",
    "\n",
    "test_confusion_matrix = pd.crosstab(Y_test, test_pred)\n",
    "test_negative_reviews = test_confusion_matrix.iloc[0,0]\n",
    "test_false_negative_reviews = test_confusion_matrix.iloc[1,0]\n",
    "test_positive_reviews = test_confusion_matrix.iloc[1,1]\n",
    "test_false_positive_reviews = test_confusion_matrix.iloc[0,1]\n",
    "\n",
    "test_sensitivity = test_negative_reviews/(test_negative_reviews + test_false_negative_reviews)\n",
    "test_specificity = test_positive_reviews/(test_positive_reviews + test_false_positive_reviews)\n",
    "print('-----------------------------------------------------------------------')\n",
    "print('{}% of the negative review predictions were correct in the test set.'.format(round(test_sensitivity*100, 0)))\n",
    "print('{}% of the positive review predictions were correct in the test set.'.format(round(test_specificity*100, 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results of version 4 model compared to original model\n",
    "- overall accuracy declined to 56% from 76%.\n",
    "- sensitivity increased to 87% from 84%. This means the phrases helped in identifying the negative reviews.\n",
    "- specificity decreased to 53% from 74%. This means the phrases hinder identifying the positive reviews."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Version 5 - Multinomial instead of Bernoulli parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_keywords = ['the', 'not', \"don't\", 'good', 'would', 'never', 'time', 'ever', 'badly',\n",
    "                      'minutes', \"won't\", 'bad', 'much', 'again', 'worst', 'disappointed', \n",
    "                      'really', 'slow', 'waited', 'wait', 'bland', 'flavor', 'experience', 'best', \n",
    "                      'terrible', 'rude', 'cold', 'taste', 'overpriced', 'poor', 'mediocre', \n",
    "                      'management', 'off', 'impressed', 'money', 'horrible', 'sick', 'waiter', 'tasted', 'nasty', \n",
    "                      'great', 'angry', 'honestly', 'care', 'disgusted', 'recommended', 'not worth', 'amazing', \n",
    "                      'liked', 'hour', 'dirty', 'clean', 'unfortunately', 'worse', 'friendly', 'love', 'loved', \n",
    "                      'absolutely', 'excellent', 'recommend', 'wonderful', 'delicious', 'fantastic', 'incredible', \n",
    "                      'nice', 'disappointment', 'tasteless', 'enjoyed', 'waste', 'authentic', 'homemade', 'worse',\n",
    "                     'pleasant', 'pleased', 'outstanding', 'generous', 'insulted', 'soggy', 'lacking', 'sad',\n",
    "                     'stale', 'helpful', 'sucks', 'beautiful', 'i', 'very', 'food', 'rotten', 'spoiled', 'stomach',\n",
    "                     'only', 'fresh']\n",
    "sentiment_phrases_2word = ['be back', 'i would', \"wont' be\", 'very good', 'i love', 'would not', \n",
    "                    'so good', 'not good', 'here again', 'will never', 'good food', 'great place', 'great food', \n",
    "                     'really good', 'customer service', '5 stars', 'at best', 'not like', 'at all', 'thumbs up',\n",
    "                    'great service', 'definitely not', 'definitely will', 'highly recommend', 'highly recommended',\n",
    "                          'very disappointing', 'not pleasant', 'not pleased', 'not helpful', 'good quality',\n",
    "                          'bad quality', 'not fresh', 'not nice']\n",
    "\n",
    "sentiment_phrases_3word = [\"won't be back\", 'will be back', \"won't be going\", 'will never ever', \n",
    "                           \"won't be disappointed\", 'back anytime soon', 'would not recommend', 'service was slow', ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in sentiment_keywords:\n",
    "    yelp_df[word] = yelp_df['review'].str.contains(word, case=False)\n",
    "\n",
    "for phrase in sentiment_phrases_2word:\n",
    "    yelp_df[phrase] = yelp_df['review'].str.contains(phrase, case=False)\n",
    "\n",
    "for phrase in sentiment_phrases_3word:\n",
    "    yelp_df[phrase] = yelp_df['review'].str.contains(phrase, case=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = yelp_df[sentiment_keywords + sentiment_phrases_2word + sentiment_phrases_3word]\n",
    "target = yelp_df['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model correctly classified 81.0% of the training set.\n",
      "This model correctly classified 76.0% of the test set.\n",
      "---------------------------------------------------------\n",
      "88.0% of the negative review predictions were correct in the training set.\n",
      "76.0% of the positive review predictions were correct in the training set.\n",
      "-----------------------------------------------------------------------\n",
      "83.0% of the negative review predictions were correct in the test set.\n",
      "71.0% of the positive review predictions were correct in the test set.\n"
     ]
    }
   ],
   "source": [
    "X = data\n",
    "Y = target\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=.2, random_state=200)\n",
    "\n",
    "bnb = MultinomialNB()\n",
    "\n",
    "bnb.fit(X_train, Y_train)\n",
    "\n",
    "training_pred = bnb.predict(X_train)\n",
    "test_pred = bnb.predict(X_test)\n",
    "\n",
    "print('This model correctly classified {}% of the training set.'.format(100*round((Y_train == training_pred).sum()/800,2)))\n",
    "print('This model correctly classified {}% of the test set.'.format(100*round((Y_test == test_pred).sum()/200,2)))\n",
    "print('---------------------------------------------------------')\n",
    "\n",
    "training_confusion_matrix = pd.crosstab(Y_train, training_pred)\n",
    "training_negative_reviews = training_confusion_matrix.iloc[0,0]\n",
    "training_false_negative_reviews = training_confusion_matrix.iloc[1,0]\n",
    "training_positive_reviews = training_confusion_matrix.iloc[1,1]\n",
    "training_false_positive_reviews = training_confusion_matrix.iloc[0,1]\n",
    "\n",
    "training_sensitivity = training_negative_reviews/(training_negative_reviews + training_false_negative_reviews)\n",
    "training_specificity = training_positive_reviews/(training_positive_reviews + training_false_positive_reviews)\n",
    "\n",
    "print('{}% of the negative review predictions were correct in the training set.'.format(round(training_sensitivity*100, 0)))\n",
    "print('{}% of the positive review predictions were correct in the training set.'.format(round(training_specificity*100, 0)))\n",
    "\n",
    "test_confusion_matrix = pd.crosstab(Y_test, test_pred)\n",
    "test_negative_reviews = test_confusion_matrix.iloc[0,0]\n",
    "test_false_negative_reviews = test_confusion_matrix.iloc[1,0]\n",
    "test_positive_reviews = test_confusion_matrix.iloc[1,1]\n",
    "test_false_positive_reviews = test_confusion_matrix.iloc[0,1]\n",
    "\n",
    "test_sensitivity = test_negative_reviews/(test_negative_reviews + test_false_negative_reviews)\n",
    "test_specificity = test_positive_reviews/(test_positive_reviews + test_false_positive_reviews)\n",
    "print('-----------------------------------------------------------------------')\n",
    "print('{}% of the negative review predictions were correct in the test set.'.format(round(test_sensitivity*100, 0)))\n",
    "print('{}% of the positive review predictions were correct in the test set.'.format(round(test_specificity*100, 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are very similar to the original model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Version 6 (using the vaderSentiment library)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "vader_pos_sentiment = []\n",
    "vader_neg_sentiment = []\n",
    "vader_compound_sentiment = []\n",
    "\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "for review in yelp_df['review']:\n",
    "    vader_pos_sentiment.append(analyzer.polarity_scores(review)['pos'])\n",
    "    vader_neg_sentiment.append(analyzer.polarity_scores(review)['neg'])\n",
    "    vader_compound_sentiment.append(analyzer.polarity_scores(review)['compound'])\n",
    "\n",
    "yelp_df['vader_pos_sentiment'] = vader_pos_sentiment\n",
    "yelp_df['vader_neg_sentiment'] = vader_neg_sentiment\n",
    "yelp_df['vader_compound_sentiment'] = vader_compound_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model correctly classified 81.0% of the training set.\n",
      "This model correctly classified 82.0% of the test set.\n",
      "---------------------------------------------------------\n",
      "81.0% of the negative review predictions were correct in the training set.\n",
      "81.0% of the positive review predictions were correct in the training set.\n",
      "-----------------------------------------------------------------------\n",
      "82.0% of the negative review predictions were correct in the test set.\n",
      "82.0% of the positive review predictions were correct in the test set.\n"
     ]
    }
   ],
   "source": [
    "yelp_df['pos_minus_neg'] = yelp_df['vader_pos_sentiment'] - yelp_df['vader_neg_sentiment']\n",
    "\n",
    "data = yelp_df[['pos_minus_neg']]\n",
    "target = yelp_df['sentiment']\n",
    "\n",
    "X = data\n",
    "Y = target\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=.2, random_state=200)\n",
    "\n",
    "bnb = BernoulliNB()\n",
    "\n",
    "bnb.fit(X_train, Y_train)\n",
    "\n",
    "training_pred = bnb.predict(X_train)\n",
    "test_pred = bnb.predict(X_test)\n",
    "\n",
    "print('This model correctly classified {}% of the training set.'.format(100*round((Y_train == training_pred).sum()/800,2)))\n",
    "print('This model correctly classified {}% of the test set.'.format(100*round((Y_test == test_pred).sum()/200,2)))\n",
    "print('---------------------------------------------------------')\n",
    "\n",
    "training_confusion_matrix = pd.crosstab(Y_train, training_pred)\n",
    "training_negative_reviews = training_confusion_matrix.iloc[0,0]\n",
    "training_false_negative_reviews = training_confusion_matrix.iloc[1,0]\n",
    "training_positive_reviews = training_confusion_matrix.iloc[1,1]\n",
    "training_false_positive_reviews = training_confusion_matrix.iloc[0,1]\n",
    "\n",
    "training_sensitivity = training_negative_reviews/(training_negative_reviews + training_false_negative_reviews)\n",
    "training_specificity = training_positive_reviews/(training_positive_reviews + training_false_positive_reviews)\n",
    "\n",
    "print('{}% of the negative review predictions were correct in the training set.'.format(round(training_sensitivity*100, 0)))\n",
    "print('{}% of the positive review predictions were correct in the training set.'.format(round(training_specificity*100, 0)))\n",
    "\n",
    "test_confusion_matrix = pd.crosstab(Y_test, test_pred)\n",
    "test_negative_reviews = test_confusion_matrix.iloc[0,0]\n",
    "test_false_negative_reviews = test_confusion_matrix.iloc[1,0]\n",
    "test_positive_reviews = test_confusion_matrix.iloc[1,1]\n",
    "test_false_positive_reviews = test_confusion_matrix.iloc[0,1]\n",
    "\n",
    "test_sensitivity = test_negative_reviews/(test_negative_reviews + test_false_negative_reviews)\n",
    "test_specificity = test_positive_reviews/(test_positive_reviews + test_false_positive_reviews)\n",
    "print('-----------------------------------------------------------------------')\n",
    "print('{}% of the negative review predictions were correct in the test set.'.format(round(test_sensitivity*100, 0)))\n",
    "print('{}% of the positive review predictions were correct in the test set.'.format(round(test_specificity*100, 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results of version 6 model compared to original model\n",
    "- The model is no longer overfit\n",
    "- overall accuracy increased to 82% from 76%.\n",
    "- sensitivity decreased to 81% from 84%. This means the negative keywords helped identify the negative reviews.\n",
    "- specificity increased tp 82% from 74%. This means the negative keywords hindered indentifying the positive reviews."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Version 6 was the best performing model. It appears the vader sentiment analyzer is the best feature for predicting sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
